{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a879bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Loaded data for 5 methods in the specified order.\n",
      "Success! Compact LaTeX tables generated at results/test/tables/appendix_perturbation_tables.tex\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "METHOD_ORDER = [\n",
    "    'sac_ae',\n",
    "    'drqv2',\n",
    "    'madi',\n",
    "    'sada',\n",
    "    'segdac_sac_sam_enc_decoder_q_cond',\n",
    "]\n",
    "METHOD_DISPLAY_NAMES = {\n",
    "    'sac_ae': 'SAC AE',\n",
    "    'drqv2': 'DrQ-v2',\n",
    "    'madi': 'MaDi',\n",
    "    'sada': 'SADA',\n",
    "    'segdac_sac_sam_enc_decoder_q_cond': 'SegDAC'\n",
    "}\n",
    "\n",
    "TASK_DISPLAY_NAMES = {\n",
    "    \"pushcubetest-v1\": \"PushCube\",\n",
    "    \"pullcubetest-v1\": \"PullCube\", \n",
    "    \"pickcubetest-v1\": \"PickCube\",\n",
    "    \"pokecubetest-v1\": \"PokeCube\",\n",
    "    \"pullcubetooltest-v1\": \"PullCubeTool\",\n",
    "    \"liftpeguprighttest-v1\": \"LiftPegUpright\",\n",
    "    \"unitreeg1placeappleinbowltest-v1\": \"PlaceAppleInBowl\",\n",
    "    \"unitreeg1transportboxtest-v1\": \"TransportBox\"\n",
    "}\n",
    "\n",
    "DIFFICULTY_ORDER = ['easy', 'medium', 'hard']\n",
    "\n",
    "def load_and_prepare_data(json_glob_path):\n",
    "    \"\"\"\n",
    "    Loads JSON files in the specified order and discovers the dimensions\n",
    "    of the experiment, excluding the 'overall' task and sorting perturbations alphabetically.\n",
    "    \"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    all_files = list(Path().glob(json_glob_path))\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No JSON files found matching pattern: {json_glob_path}\")\n",
    "\n",
    "    file_map = {f.name.replace(\n",
    "        '_final_aggregated_scores-0.json', ''): f for f in all_files}\n",
    "    all_data = {}\n",
    "    ordered_methods = []\n",
    "    for method_name in METHOD_ORDER:\n",
    "        if method_name in file_map:\n",
    "            ordered_methods.append(method_name)\n",
    "            filepath = file_map[method_name]\n",
    "            with filepath.open('r') as file:\n",
    "                all_data[method_name] = json.load(file)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Data file for method '{method_name}' not found. Expected file: {filepath}\")\n",
    "\n",
    "    if not ordered_methods:\n",
    "        raise ValueError(\"No data could be loaded for any of the specified methods.\")\n",
    "\n",
    "    first_method = ordered_methods[0]\n",
    "    first_run_id = next(iter(all_data[first_method]))\n",
    "    sample_data = all_data[first_method][first_run_id]\n",
    "    tasks = sorted([t for t in sample_data.get(\n",
    "        'no_perturb', {}).keys() if t != 'overall'])\n",
    "\n",
    "    perturbation_tests = set()\n",
    "    perturb_indiv_data = sample_data.get('perturb_indiv', {})\n",
    "    if perturb_indiv_data:\n",
    "        for difficulty in DIFFICULTY_ORDER:\n",
    "            if difficulty in perturb_indiv_data:\n",
    "                valid_tasks_in_difficulty = [\n",
    "                    t for t in perturb_indiv_data[difficulty].keys() if t in tasks]\n",
    "                if valid_tasks_in_difficulty:\n",
    "                    first_task = valid_tasks_in_difficulty[0]\n",
    "                    perturbation_tests.update(\n",
    "                        perturb_indiv_data[difficulty][first_task].keys())\n",
    "\n",
    "    print(f\"Loaded data for {len(ordered_methods)} methods in the specified order.\")\n",
    "    return {\n",
    "        'data': all_data,\n",
    "        'methods': ordered_methods,\n",
    "        'tasks': tasks,\n",
    "        'perturbations': sorted(list(perturbation_tests))\n",
    "    }\n",
    "\n",
    "def get_cell_performance(all_data, method, task, difficulty, perturb_test):\n",
    "    \"\"\"\n",
    "    Extracts IQM, CI, and calculates the relative performance change (delta)\n",
    "    for a single table cell.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        run_id = next(iter(all_data[method]))\n",
    "        method_data = all_data[method][run_id]\n",
    "        no_perturb_iqm = method_data['no_perturb'][task]['return']['iqm'][0]\n",
    "        perturb_run = method_data['perturb_indiv'][difficulty][task][perturb_test]['return']\n",
    "        iqm = perturb_run['iqm'][0]\n",
    "        ci = perturb_run.get('ci')\n",
    "        delta = ((iqm - no_perturb_iqm) / abs(no_perturb_iqm)) * \\\n",
    "            100 if no_perturb_iqm and no_perturb_iqm != 0 else 0\n",
    "        return {'iqm': iqm, 'ci': ci, 'delta': delta}\n",
    "    except (KeyError, IndexError, TypeError):\n",
    "        return {'iqm': None, 'ci': None, 'delta': None}\n",
    "\n",
    "def format_latex_cell(data, is_bold, is_underlined):\n",
    "    \"\"\"\n",
    "    Formats the data into a compact single-line cell with performance and delta.\n",
    "    Bolds the cell if it has the highest IQM, underlines if it has the best (highest) delta.\n",
    "    \"\"\"\n",
    "    if data['iqm'] is None:\n",
    "        return 'N/A'\n",
    "\n",
    "    if data['ci'] and len(data['ci']) == 2:\n",
    "        half_width = (data['ci'][1][0] - data['ci'][0][0]) / 2\n",
    "        score_str = f\"{data['iqm']:.2f}$\\\\pm${half_width:.2f}\"\n",
    "    else:\n",
    "        score_str = f\"{data['iqm']:.2f}\"\n",
    "\n",
    "    delta_str = f\"({data['delta']:+.1f}\\\\%)\"\n",
    "    \n",
    "    full_cell_str = f\"{score_str} \\\\scriptsize{{{delta_str}}}\"\n",
    "    \n",
    "    if is_bold and is_underlined:\n",
    "        return f\"\\\\textbf{{\\\\underline{{{full_cell_str}}}}}\"\n",
    "    elif is_bold:\n",
    "        return f\"\\\\textbf{{{full_cell_str}}}\"\n",
    "    elif is_underlined:\n",
    "        return f\"\\\\underline{{{full_cell_str}}}\"\n",
    "    else:\n",
    "        return full_cell_str\n",
    "\n",
    "def generate_latex_tables(json_glob_path, output_dir):\n",
    "    \"\"\"Main function to generate the complete LaTeX file with compact formatting.\"\"\"\n",
    "    try:\n",
    "        experimental_data = load_and_prepare_data(json_glob_path)\n",
    "    except (FileNotFoundError, ValueError, IndexError) as e:\n",
    "        print(f\"Error initializing data: {e}\")\n",
    "        return\n",
    "\n",
    "    output_path = Path(output_dir) / 'appendix_perturbation_tables.tex'\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    all_methods = experimental_data['methods']\n",
    "\n",
    "    with output_path.open('w') as f:\n",
    "        f.write(\"% This file was automatically generated by a Python script.\\n\")\n",
    "        f.write(\"% Required packages: \\\\usepackage{booktabs}, \\\\usepackage{array}\\n\")\n",
    "        f.write(\"% Optional for better spacing: \\\\usepackage{tabularx}\\n\\n\")\n",
    "\n",
    "        for difficulty in DIFFICULTY_ORDER:\n",
    "            for perturb_test in experimental_data['perturbations']:\n",
    "                table_has_data = False\n",
    "                table_body_rows = []\n",
    "                \n",
    "                for task in experimental_data['tasks']:\n",
    "                    row_results = [get_cell_performance(\n",
    "                        experimental_data['data'], m, task, difficulty, perturb_test) \n",
    "                        for m in all_methods]\n",
    "                    \n",
    "                    if any(r['iqm'] is not None for r in row_results):\n",
    "                        table_has_data = True\n",
    "\n",
    "                    # Find highest IQM (for bold)\n",
    "                    valid_iqms = [r['iqm'] for r in row_results if r['iqm'] is not None]\n",
    "                    max_iqm = max(valid_iqms) if valid_iqms else -math.inf\n",
    "                    max_iqm_rounded = round(max_iqm, 2)\n",
    "\n",
    "                    # Find highest delta (for underline) - higher is better (less negative or more positive)\n",
    "                    valid_deltas = [r['delta'] for r in row_results if r['delta'] is not None]\n",
    "                    max_delta = max(valid_deltas) if valid_deltas else -math.inf\n",
    "                    max_delta_rounded = round(max_delta, 1)\n",
    "\n",
    "                    formatted_cells = []\n",
    "                    for r in row_results:\n",
    "                        iqm_round = round(r['iqm'], 2) if r['iqm'] is not None else None\n",
    "                        delta_round = round(r['delta'], 1) if r['delta'] is not None else None\n",
    "\n",
    "                        is_bold = (iqm_round is not None and iqm_round == max_iqm_rounded)\n",
    "                        is_underlined = (delta_round is not None and delta_round == max_delta_rounded)\n",
    "\n",
    "                        formatted_cells.append(format_latex_cell(r, is_bold, is_underlined))\n",
    "\n",
    "                    task_name = TASK_DISPLAY_NAMES.get(task, task)\n",
    "                    table_body_rows.append(f\"{task_name} & {' & '.join(formatted_cells)} \\\\\\\\\")\n",
    "\n",
    "                if not table_has_data:\n",
    "                    continue\n",
    "\n",
    "                # Generate table\n",
    "                caption_perturb = perturb_test.replace('_', ' ').title()\n",
    "                label_perturb = perturb_test.replace('_', '')\n",
    "                header_names = [METHOD_DISPLAY_NAMES.get(m, m) for m in all_methods]\n",
    "\n",
    "                col_format = f\"l*{{{len(all_methods)}}}{{c}}\"\n",
    "                \n",
    "                bold_header_names = [f\"\\\\textbf{{{name}}}\" for name in header_names]\n",
    "                header_line = f\"\\\\textbf{{Task}} & {' & '.join(bold_header_names)} \\\\\\\\\"\n",
    "\n",
    "                f.write(f\"% Table for: {caption_perturb} ({difficulty})\\n\")\n",
    "                f.write(\"\\\\begin{table}[htbp]\\n\")\n",
    "                f.write(\"\\\\centering\\n\")\n",
    "                f.write(\"\\\\scriptsize\\n\")\n",
    "                f.write(f\"\\\\caption{{{difficulty.title()} {caption_perturb}}}\\n\")\n",
    "                f.write(f\"\\\\label{{tab:appendix_{label_perturb}_{difficulty}}}\\n\")\n",
    "                f.write(\"\\\\begin{adjustbox}{max width=\\\\textwidth}\\n\")\n",
    "                f.write(f\"\\\\begin{{tabular}}{{{col_format}}}\\n\")\n",
    "                f.write(\"\\\\toprule\\n\")\n",
    "                f.write(header_line + \"\\n\")\n",
    "                f.write(\"\\\\midrule\\n\")\n",
    "                f.write(\"\\n\".join(table_body_rows) + \"\\n\")\n",
    "                f.write(\"\\\\bottomrule\\n\")\n",
    "                f.write(\"\\\\end{tabular}\\n\")\n",
    "                f.write(\"\\\\end{adjustbox}\\n\")\n",
    "                f.write(\"\\\\end{table}\\n\\n\")\n",
    "\n",
    "    print(f\"Success! Compact LaTeX tables generated at {output_path}\")\n",
    "\n",
    "JSON_GLOB_PATH = 'results/test/*_final_aggregated_scores-0.json'\n",
    "OUTPUT_DIRECTORY = 'results/test/tables'\n",
    "\n",
    "generate_latex_tables(JSON_GLOB_PATH, OUTPUT_DIRECTORY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maniskill3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
